{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Reuters Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget that you can link your notebook to your drive and save your work there. Then you can download and backup your models, reload them to keep training them, or upload datasets to your drive. \n",
    "\n",
    "```python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    os.chdir('drive/My Drive/') # 'My Drive' is the default name of Google Drives\n",
    "    os.listdir()\n",
    "    \n",
    "# use os.chdir(\"my-directory\") # to change directory, and\n",
    "# os.listdir()                 # to list its contents\n",
    "# os.getcwd()                  # to get the name of the current directory\n",
    "# os.mkdir(\"my-new-dir\")       # to create a new directory\n",
    "# See: https://realpython.com/working-with-files-in-python/\n",
    "\n",
    "# You can also use bash commands directly, preceded by a bang\n",
    "# !ls\n",
    "# However, the following will *not* change the Python directory \n",
    "# the notebook points to (use os.chdir for that)!\n",
    "# !cd my-directory    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8RmLzZjj3Hl"
   },
   "source": [
    "### For reproducible results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8RmLzZjj3Hl"
   },
   "source": [
    "In Keras ([source](https://keras.io/examples/keras_recipes/reproducibility_recipes/)):\n",
    "```python\n",
    "keras.utils.set_random_seed(812) # See below\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "```\n",
    "\n",
    "Note: `keras.utils.set_random_seed` will do the following ([source](https://github.com/keras-team/keras/blob/d66ecf029e4864eeeff7e22408e82c95d63422d0/keras/src/utils/rng_utils.py#L58)):\n",
    "\n",
    "```python\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# if tf as backend\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# if torch as backend\n",
    "torch.manual_seed(42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset processing & model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "# load\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.reuters.load_data(num_words=10000)\n",
    "\n",
    "# preprocess\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "one_hot_train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "one_hot_test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "# split training set into train & validation\n",
    "partial_x_train=x_train[1000:]\n",
    "partial_y_train=one_hot_train_labels[1000:]\n",
    "x_val=x_train[:1000]\n",
    "y_val=one_hot_train_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input((10000,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Do you remember the baseline discussion in the lecture? You can import the code and test it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = []\n",
    "for test in test_labels: # ↓ a random number between 0 and 45\n",
    "    attempts.append(np.random.randint(46) == test)\n",
    "print(np.mean(attempts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is insufficient, as the Reuters dataset is imbalanced, and some classes more prevalent than others. In this case, our baseline is the accuracy obtained when **predicting the most prevalent/likely class**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we could also use a counter:\n",
    "from collections import Counter\n",
    "c = Counter(test_labels)\n",
    "indx = c.most_common(n=1)[0][0] # ← you could ask for the n most common items\n",
    "\n",
    "# a plain loop will give us the same result\n",
    "attempts = []\n",
    "for test in test_labels: # only predict the most prevalent class\n",
    "    attempts.append(indx == test)\n",
    "print(f\"The accuracy baseline to beat (if we predict the most prevalent class):\", np.mean(attempts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that an accuracy of `0.3619768477292965`, the probability of the likeliest class, is higher than the random guess (this is always the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Sanity check, how does our network perform before training (use `.evaluate` on `partial_x_train, partial_y_train`). Is the accuracy a value you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels, verbose=0) # our untrained model\n",
    "print(f\"test loss: {results[0]}, test accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it is even worse than the random guess!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val,y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `matplotlib` code to visualise the result of your experiments (from lab 3 or the lectures).\n",
    "\n",
    "Can you think of ways to make the code easy to reuse (when running several experiments)?\n",
    "\n",
    "As usual, we are after the epoch where best *validation* result (accuracy) has been achieved. Can you think of a way to retrieve that optimal epoch programmatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    history_dict = history.history\n",
    "    loss = history_dict[\"loss\"]\n",
    "    val_loss = history_dict[\"val_loss\"]\n",
    "    acc = history_dict[\"accuracy\"]\n",
    "    val_acc = history_dict[\"val_accuracy\"]    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    # plot loss and acc horizontally\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(9,1.7)) \n",
    "    axs[0].plot(epochs, loss, label=\"Training loss\")\n",
    "    axs[0].plot(epochs, val_loss, \"--\", label=\"Validation loss\")\n",
    "    axs[0].set_title(\"Training and validation loss\", fontsize=12)\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(epochs, acc, label=\"Training acc\")\n",
    "    axs[1].plot(epochs, val_acc, \"--\", label=\"Validation acc\")\n",
    "    axs[1].set_title(\"Training and validation acc\", fontsize=12)\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].legend()    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_epoch = np.argmax(history.history[\"val_accuracy\"])\n",
    "best_acc = history.history[\"val_accuracy\"][best_acc_epoch]\n",
    "\n",
    "print(f\"The best validation accuracy, {best_acc} was reachded at epoch {best_acc_epoch}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot training and validation loss and accuracy. Can you spot the optimal epoch (where the best *validation accuracy* has been achieved)?\n",
    "- Deliberately cause an information bottleneck by building a 64-4-46 network. Compare the validation accuracy with a 64-64-46 network;\n",
    "- Try using larger layers – 128 units and smaller layers – 32 units;\n",
    "- Try less and more hidden layers;\n",
    "- Tabulate your results / organise your experiments as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of collecting the best accuracy data manually proved to be quite tedious, when working on MNIST. Here instead, I will implement **grid search** again, for various parameters. I will also restrict my search to smaller models and fewer epochs, as a proof of concept, and so that my experiment cycle is faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    history_dict = history.history\n",
    "    loss = history_dict[\"loss\"]\n",
    "    val_loss = history_dict[\"val_loss\"]\n",
    "    acc = history_dict[\"accuracy\"]\n",
    "    val_acc = history_dict[\"val_accuracy\"]    \n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    # plot loss and acc horizontally\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(9,1.7)) \n",
    "    axs[0].plot(epochs, loss, label=\"Training loss\")\n",
    "    axs[0].plot(epochs, val_loss, \"--\", label=\"Validation loss\")\n",
    "    axs[0].set_title(\"Training and validation loss\", fontsize=12)\n",
    "    axs[0].set_xlabel(\"Epochs\")\n",
    "    axs[0].set_ylabel(\"Loss\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].plot(epochs, acc, label=\"Training acc\")\n",
    "    axs[1].plot(epochs, val_acc, \"--\", label=\"Validation acc\")\n",
    "    axs[1].set_title(\"Training and validation acc\", fontsize=12)\n",
    "    axs[1].set_xlabel(\"Epochs\")\n",
    "    axs[1].set_ylabel(\"Accuracy\")\n",
    "    axs[1].legend()    \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# plot_history(history) # test with the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(layers, optimizer, lr, epochs=10, mode=\"experiment\", clear=True):\n",
    "    \"\"\"\n",
    "    Trainer with two modes:\n",
    "     - \"experiment\" (partial train + val)\n",
    "     - \"final\" (train + no val)\n",
    "\n",
    "    returns:\n",
    "        model, history\n",
    "    \"\"\"\n",
    "    if clear:\n",
    "        tf.keras.backend.clear_session()\n",
    "    opt = optimizer(lr) # instatiate the optimizer (so we can retrieve its name, hehe)\n",
    "    print(f\"Training model with:\")\n",
    "    print(f\" - {len(layers)} layer(s) with units: {layers}\")\n",
    "    print(f\" - {opt.name}(lr={lr})\")\n",
    "    print(f\" - # epochs: {epochs}\")\n",
    "    \n",
    "    # build\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input((10000,)))\n",
    "    for n_units in layers:\n",
    "        model.add(tf.keras.layers.Dense(n_units, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(46, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    if mode == \"experiment\":\n",
    "        # save data from training into the 'history' object\n",
    "        history = model.fit(\n",
    "            partial_x_train,\n",
    "            partial_y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=128,\n",
    "            validation_data=(x_val, y_val),\n",
    "            verbose=0, # no need for all this logging\n",
    "        )\n",
    "        model = None # save memory\n",
    "        \n",
    "    elif mode == \"final\":\n",
    "        # train on the entire training data\n",
    "        history = model.fit(\n",
    "            x_train,\n",
    "            one_hot_train_labels,\n",
    "            epochs=epochs,\n",
    "            batch_size=128,\n",
    "            # no validation\n",
    "            verbose=0, # no need for all this logging\n",
    "        )\n",
    "    return model, history\n",
    "\n",
    "def best_val_performance(history):\n",
    "    top_val_acc_epoch = np.argmax(history.history[\"val_accuracy\"])\n",
    "    top_val_acc = history.history[\"val_accuracy\"][top_val_acc_epoch]\n",
    "    print()\n",
    "    print(\"Results:\")\n",
    "    print(f\"Top validation accuracy: {top_val_acc}, reached at epoch: {top_val_acc_epoch}.\")\n",
    "    return top_val_acc, top_val_acc_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 1\n",
    "\n",
    "- Information bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our set-up, we will replicate the experiment seen in the lecture: firs, we train a model with two layers of $64$ units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64,64]\n",
    "opt = tf.keras.optimizers.Adam\n",
    "lr = 0.001\n",
    "_, hist = trainer(layers, opt, lr)\n",
    "_ = best_val_performance(hist)\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance increases relatively smoothly, and we only start overfitting at epoch 9.\n",
    "\n",
    "Now, we can create a bottleneck by having a second layer with far fewer units ($4$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [64, 4]\n",
    "opt = tf.keras.optimizers.Adam\n",
    "lr = 0.001\n",
    "_, hist = trainer(layers, opt, lr)\n",
    "_ = best_val_performance(hist)\n",
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance degrades very significantly, to only $57\\%$ accuracy! Also, the accuracy progression does not behave as expected, with a jump between epochs 2 and 4!, followed by relative stagnation at this accuracy level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 2\n",
    "\n",
    "- Grid search with a hand-made tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def tuner():\n",
    "    units = [8,12,16]\n",
    "    layers = [1,2,3]\n",
    "    # construct layers: e.g. 2 * [8] = [8, 8] in Python\n",
    "    model_layers = [l * [u] for l, u in list(product(layers, units))]\n",
    "    optimizers = [tf.keras.optimizers.Adam, tf.keras.optimizers.Adam]\n",
    "    learning_rates = [0.001, 0.002, 0.003]   \n",
    "\n",
    "    # TODO: try use a dictionary instead\n",
    "    all_histories = []\n",
    "    all_accs = []\n",
    "    all_accs_epochs = []\n",
    "    all_params = []\n",
    "    for layers in model_layers:\n",
    "            for opt in optimizers:\n",
    "                for lr in learning_rates:\n",
    "                    # train our model\n",
    "                    _, hist = trainer(layers, opt, lr, epochs=5)\n",
    "                    # plot the history (TODO: try plot all experiments on one plot?)\n",
    "                    plot_history(hist)\n",
    "                    acc, acc_epoch = best_val_performance(hist)\n",
    "                    all_histories.append(hist)\n",
    "                    all_accs.append(acc)\n",
    "                    all_accs_epochs.append(acc_epoch)\n",
    "                    all_params.append({\"layers\":layers, \"opt\": opt, \"lr\": lr})\n",
    "                    print(\"-\" * 100)\n",
    "                    print()\n",
    "                    \n",
    "    return all_histories, all_accs, all_accs_epochs, all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_histories, all_accs, all_accs_epochs, all_params = tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_experiments(all_histories, all_accs, all_accs_epochs, all_params):\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    msg = \"Result of this experiment:\"\n",
    "    print(msg)\n",
    "    print(\"-\" * len(msg))\n",
    "\n",
    "    longest_l = len(str(max([str(p[\"layers\"]) for p in all_params], key=len)))\n",
    "    longest_o = len(str(max([p[\"opt\"]().name for p in all_params], key=len)))\n",
    "    # f-strings in Python: https://www.w3schools.com/python/python_string_formatting.asp\n",
    "    for acc, epoch, params in zip(all_accs, all_accs_epochs, all_params):\n",
    "        print(f\" - layers: {str(params['layers']):>{longest_l}}, {params['opt']().name:>{longest_o}}(lr={params['lr']}) | top val accuracy: {acc:.6f} at epoch: {epoch}\")\n",
    "    \n",
    "    # sort my results \n",
    "    sorted_indz = np.argsort(all_accs)\n",
    "\n",
    "    # select the the best one\n",
    "    best_acc = np.array(all_accs)[sorted_indz][-1]\n",
    "    best_epoch = np.array(all_accs_epochs)[sorted_indz][-1]\n",
    "    best_params = np.array(all_params)[sorted_indz][-1]\n",
    "    \n",
    "    print()\n",
    "    print(\"-\" * 100)\n",
    "    msg = \"Best model found:\"\n",
    "    print(msg)\n",
    "    print(\"-\" * len(msg))\n",
    "    print(f\"Validation accuracy: {best_acc} reached at epoch: {best_epoch}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(f\" - {best_params['layers']} layers\")\n",
    "    print(f\" - {best_params['opt']().name}(lr={best_params['lr']})\")\n",
    "    print(\"-\" * len(msg))\n",
    "\n",
    "    return best_params, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_epoch = display_experiments(all_histories, all_accs, all_accs_epochs, all_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for expansion:\n",
    "- I focussed on building a small tuner system, rather than experimenting with all possible directions outlined in the brief. This system could be expanded to explore the hyperparameter space in even more detail.\n",
    "- Given enough time, training for more epochs is likely to improve performance in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Take your best network and train on **all the training data** (`x_train`, `one_hot_train_labels`), without a train/validation split, using the same hyperparameters (optimizer, learning rate, network size, etc.) as your best run, for the optimal number of epochs (looking at your best validation curves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _ = trainer(\n",
    "    best_params['layers'],\n",
    "    best_params['opt'],\n",
    "    best_params['lr'],\n",
    "    best_epoch,\n",
    "    mode=\"final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this last model on the test set (`x_test, one_hot_test_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(\"Final results:\")\n",
    "print(f\"Loss: {result[0]}, accuracy: {result[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to reach $0.7212823033332825$, around $72\\%$ accuracy, on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Use your model (optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Can you import the lecture code used to test the model on a newswire, and see if you agree with its prediction?\n",
    "\n",
    "AS shown in the lecture, the 46 topics are:\n",
    "```python\n",
    "# https://github.com/keras-team/keras/issues/12072\n",
    "# and here: https://martin-thoma.com/nlp-reuters/\n",
    "topics = [\n",
    "    'cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "    'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "    'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "    'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "    'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead'\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_wire(wire):\n",
    "    \"\"\"A helper function to decode a wire.\"\"\"\n",
    "    word_index = tf.keras.datasets.reuters.get_word_index()\n",
    "    reverse_word_index = {value:key for key,value in word_index.items()}\n",
    "    decoded_wire = ' '.join([reverse_word_index.get(i - 3, '?') for i in wire])\n",
    "    return decoded_wire\n",
    "\n",
    "def classify_wire(dataset_split, index):\n",
    "    topics = [\n",
    "        'cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "        'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "        'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "        'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "        'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead'\n",
    "    ]\n",
    "    labels = y_train if dataset_split == \"train\" else y_test\n",
    "    dataset = train_data if dataset_split == \"train\" else test_data\n",
    "    vectorized_dataset = x_train if dataset_split == \"train\" else x_test\n",
    "    predictions = model.predict(vectorized_dataset[index:index+1], verbose=0)[0]\n",
    "    pred = np.argmax(predictions)\n",
    "    correct = pred == int(labels[index])\n",
    "    print(f\"predicted: {topics[pred]}, label: {topics[int(labels[index])]} | {'✓' if correct else '✗'}\")\n",
    "    print()\n",
    "    print(decode_wire(dataset[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    split = np.random.choice([\"train\", \"test\"])\n",
    "    index = np.random.randint(0,100) # improvement: fetch the max of train/test depending on split\n",
    "    print(f\"split: {split}, wire #{index}\")\n",
    "    classify_wire(split, index)\n",
    "    print()\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save and load models locally, you can use [the high-level API](https://www.tensorflow.org/tutorials/keras/save_and_load):\n",
    "```python\n",
    "model.save(\"my_reuters_model.keras\")\n",
    "```\n",
    "Later one, to reload it, use:\n",
    "```python\n",
    "reloaded_model = tf.keras.models.load_model('my_reuters_model.keras')\n",
    "```\n",
    "\n",
    "It is also possible to save not just the model, but also the state of your optimiser, and every variable used during training, using the more involved [checkpoints](https://www.tensorflow.org/guide/checkpoint#create_the_checkpoint_objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Additional experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Like in the IMDB dataset, one parameter you could study is the influence on the vocabulary size on the final results: you might then want to store the vocab size in a variable, and use that instead of the hard-coded `10000` that we have.\n",
    "- Another line of enquiry is the study of the behaviour of your trained model:\n",
    "  - Are you able to modify existing wire in a way that changes the initial prediction of your model? (One 'automated' way of doing that would be to remove a certain number of words from the review, and see how performance is impacted by that information loss.)\n",
    "  - Are you able to create a pipeline where you write your own review, or find one online, transform it into the appropriate format (remove punctuation, turn everything to lower case, convert to an array of integers using the dictionary yielded by `tf.keras.datasets.reuters.get_word_index()` (beware of the shift by 3 induced by the reserved tokens for padding, start of sequence and unknown!), and see what prediction you get for it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tf.keras.datasets.reuters.get_word_index()\n",
    "reverse_word_index = {value:key for key,value in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = { k:v for k,v in word_index.items() if v <= 10000}\n",
    "reverse_word_index = {value:key for key,value in word_index.items()}\n",
    "\n",
    "def process_wire(rev, verbose=False):\n",
    "    # lower case + + no newlines + no punctuation + split on space\n",
    "    rev = rev.lower().replace(\"\\n\", \" \").translate(str.maketrans('', '', string.punctuation)).split(\" \")\n",
    "    if verbose:\n",
    "        print(rev)\n",
    "    # 0 for padding, 1 for start of sequence, 2 for unknown\n",
    "    # adding 3 to the word index to account for the first reserved tokens\n",
    "    # using `.get()`: if w is not in word_index, use -1+3 = 2: 'unknown'\n",
    "    rev_encoded = [word_index.get(w, -1) + 3 for w in rev]\n",
    "    if verbose:\n",
    "        print(rev_encoded)\n",
    "        print()\n",
    "    return rev_encoded\n",
    "\n",
    "def print_wire(wire_arr, label):\n",
    "    topics = [\n",
    "        'cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "        'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "        'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "        'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "        'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead'\n",
    "    ]\n",
    "    \n",
    "    decoded_wire = ' '.join([reverse_word_index.get(i - 3, \"?\") for i in wire_arr])\n",
    "    wire_multihot_batch = vectorize_sequences([wire_arr])\n",
    "    # print(wire_multihot_batch.shape)\n",
    "    predictions = model.predict(wire_multihot_batch, verbose=0)[0]\n",
    "    plt.figure(figsize=(10,2))\n",
    "    plt.bar(range(1, len(topics)+1), predictions)\n",
    "    plt.xticks(range(1, len(topics)+1), labels=topics, fontsize=8, rotation=90)\n",
    "    plt.show()\n",
    "    pred = np.argmax(predictions)\n",
    "    print(f\"Label predicted for manually written wire: {topics[pred]}\")\n",
    "    print()\n",
    "    print(decoded_wire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test a few reviews found on the Reuters website. First, one found when searching for \"acquisitions\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reuters.com/business/healthcare-pharmaceuticals/abbvie-buy-alzheimers-therapy-developer-aliada-therapeutics-14-bln-2024-10-28/\n",
    "wire = \"\"\"\n",
    "U.S. drugmaker AbbVie (ABBV.N), opens new tab said on Monday it will buy Aliada Therapeutics for $1.4 billion in cash, betting on an experimental Alzheimer's treatment still in the early stage of development.\n",
    "AbbVie, with a market value of about a $330 billion, squared off against at least three other pharmaceutical companies interested in Aliada, a person familiar with the sale process said. AbbVie shares closed up 1% on Monday.\n",
    "\"\"\"\n",
    "\n",
    "# testing if the wire is correctly encoded then decoded\n",
    "print_wire(process_wire(wire, verbose=True), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkable, that seems to have worked!\n",
    "\n",
    "Next, a rewiew I found by searching \"metal feed\" on Reuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reuters.com/markets/commodities/us-copper-imports-accelerate-wake-cme-squeeze-andy-home-2024-10-24/\n",
    "wire = \"\"\"\n",
    "The May squeeze on the CME copper contract has passed but the impact on global flows of the red metal is still playing out.\n",
    "U.S. imports of copper have surged after traders capitalised on a rare arbitrage window that opened between the CME and the London Metal Exchange (LME) contracts at the height of the squeeze on CME short position holders.\n",
    "The result has been a redistribution of global exchange inventory with CME stocks rebuilding from depleted levels and both LME and Shanghai Futures Exchange (ShFE) inventory falling.\n",
    "\"\"\"\n",
    "# testing if the wire is correctly encoded then decoded\n",
    "print_wire(process_wire(wire), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprising and strange... \"crude\", even if the text talks of copper and metal??\n",
    "\n",
    "Next, a review I found by searching \"housing\" on Reuters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reuters.com/business/welltower-raises-annual-ffo-forecast-resilient-demand-senior-housing-2024-10-28/\n",
    "wire = \"\"\"\n",
    "Welltower (WELL.N), opens new tab raised its annual funds from operations forecast on Monday, betting on resilient demand for the healthcare real estate investment trust's assisted living and senior housing properties.\n",
    "The company now sees its 2024 normalized FFO, a key performance measure for REITs, in the range of $4.27 to $4.33 per share, compared with its previous estimate of $4.13 to $4.21.\n",
    "The REIT owns housing, outpatient medical centers and healthcare properties with a focus on older adults and assisted living. It operates in the United States, Canada and the United Kingdom.\n",
    "It posted quarterly normalized FFO of $1.11 per share, an increase of 20.7% from the previous year.\n",
    "\"\"\"\n",
    "# testing if the wire is correctly encoded then decoded\n",
    "print_wire(process_wire(wire), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not _quite_ what I expected, but still, predictions are being made!\n",
    "\n",
    "Let's see if the next one reflects the \"oil\" search I found it under:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.reuters.com/markets/commodities/brazils-petrobras-posts-65-fall-q3-total-production-2024-10-28/\n",
    "wire = \"\"\"\n",
    "Oil giant Petrobras' oil output in Brazil was down 8.2% year-on-year in the third quarter, to 2.13 million barrels per day (bpd), the state-controlled company said on Monday.\n",
    "Petrobras also posted a 6.5% decrease in total production in the period, to 2.69 million barrels of oil equivalent per day (boepd).\n",
    "Output from the firm's pre-salt fields, an oil-rich offshore region off the country's southeastern Atlantic coast, fell 2.7%, adding up to a decrease in production on Petrobras' other fields.\n",
    "According to Oil giant, total sales in the period were down 3.2% year-on-year, to 2.97 million bpd, while exports fell 2.3%, to 804,000 bpd.\n",
    "\"\"\"\n",
    "# testing if the wire is correctly encoded then decoded\n",
    "print_wire(process_wire(wire), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks like crude is crude. It would be a strange game to try and find at least _one_ wire that activates each of those 46 classes..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
